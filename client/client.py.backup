#!/usr/bin/env python3
"""
Wake Saiteku Client - ç«¯æœ«å´ã®Wake Wordæ¤œçŸ¥ã¨éŸ³å£°é€ä¿¡ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å„ªå…ˆã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œ
"""

import os
import sys
import time
import json
import queue
import threading
import wave
import re
import requests
import tempfile
import logging
import logging.handlers
import uuid
from pathlib import Path
from typing import Optional, Tuple, List
from dataclasses import dataclass
from datetime import datetime

import numpy as np
import sounddevice as sd
import webrtcvad

# --- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ import path ã«è¿½åŠ ï¼ˆpython client/client.py å®Ÿè¡Œå¯¾å¿œï¼‰
_PROJECT_ROOT = str(Path(__file__).resolve().parents[1])
if _PROJECT_ROOT not in sys.path:
    sys.path.insert(0, _PROJECT_ROOT)

from utils.wake_utils import recent_text_from_history, is_wake_in_text, squash_repeated_tokens, find_wake_match
from utils.text_utils import dedupe_transcript
from utils.stt_backends import create_local_stt_engine

# .env ã®è‡ªå‹•èª­ã¿è¾¼ã¿ï¼ˆä»»æ„ï¼‰
try:
    from dotenv import load_dotenv  # type: ignore
    load_dotenv(dotenv_path=Path(_PROJECT_ROOT) / ".env", override=False)
    logger = logging.getLogger(__name__)
    logger.debug(".env ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
except Exception:
    pass

# ========== ãƒ­ã‚®ãƒ³ã‚°è¨­å®š ==========
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ã‚®ãƒ³ã‚°è¨­å®šï¼ˆæ—¥æ¬¡ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
def _configure_file_logging():
    level = os.getenv("LOG_LEVEL", "INFO").upper()
    logger.setLevel(getattr(logging, level, logging.INFO))
    if os.getenv("LOG_TO_FILE", "true").lower() == "true":
        default_dir = str((Path(__file__).resolve().parents[1] / "logs").resolve())
        log_dir = os.getenv("LOG_DIR", default_dir)
        try:
            os.makedirs(log_dir, exist_ok=True)
            handler = logging.handlers.TimedRotatingFileHandler(
                os.path.join(log_dir, "client.log"), when="midnight", backupCount=7, encoding="utf-8"
            )
            handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
            logger.addHandler(handler)
        except Exception as e:
            logger.warning(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®šã«å¤±æ•—: {e}")

_configure_file_logging()

# ========== è¨­å®š ==========
@dataclass
class AudioConfig:
    SAMPLE_RATE: int = 16000
    FRAME_DUR_MS: int = 20
    CHANNELS: int = 1
    DTYPE: str = 'int16'
    INPUT_DEVICE: Optional[str] = os.getenv("AUDIO_INPUT_DEVICE")  # device index or name
    OUTPUT_DEVICE: Optional[str] = os.getenv("AUDIO_OUTPUT_DEVICE")  # device index or name
    
    @property
    def frame_length(self) -> int:
        return int(self.SAMPLE_RATE * self.FRAME_DUR_MS / 1000)

@dataclass
class WakeConfig:
    WAKE_TIMEOUT_S: float = float(os.getenv("WAKE_TIMEOUT_S", "4.0"))
    WAKE_REQUIRE_BOTH: bool = os.getenv("WAKE_REQUIRE_BOTH", "false").lower() == "true"
    WAKE_WORDS: List[Tuple[str, str]] = None
    
    def __post_init__(self):
        if self.WAKE_WORDS is None:
            self.WAKE_WORDS = [
                ("ã‚‚ã—ã‚‚ã—", r"ã‚‚ã—ã‚‚ã—"),
                ("ã‚µã‚¤ãƒ†ã‚¯", r"(ã‚µã‚¤ãƒ†ã‚¯|ã•ã„ã¦ã|ï½»ï½²ï¾ƒï½¸|ã•ã„ãƒ†ã‚¯|ã‚µã‚¤ãƒ†ãƒƒã‚¯|ã•ã„ã¦ã£ã|ã‚µã‚¤ãƒˆã‚¯|ã•ã„ã¨ã)")
            ]

@dataclass
class VADConfig:
    VAD_MODE: int = int(os.getenv("VAD_MODE", "2"))  # 0-3, 3ãŒæœ€ã‚‚å³ã—ã„
    MIN_UTTERANCE_MS: int = int(os.getenv("MIN_UTTERANCE_MS", "300"))
    END_SILENCE_MS: int = int(os.getenv("END_SILENCE_MS", "800"))
    HOLD_AFTER_START_MS: int = int(os.getenv("HOLD_AFTER_START_MS", "1200"))
    MAX_RECORDING_MS: int = int(os.getenv("MAX_RECORDING_MS", "10000"))

@dataclass
class ServerConfig:
    REMOTE_URL: str = os.getenv("SERVER_URL", "http://127.0.0.1:8000/inference")
    # Optional alternate URL for quick switching (e.g., legacy<->v1)
    ALT_URL: str = os.getenv("SERVER_URL_ALT", "")
    # auto | legacy | v1
    SERVER_API_MODE: str = os.getenv("SERVER_API_MODE", "auto").strip().lower()
    LOCAL_STT_ENABLED: bool = os.getenv("LOCAL_STT_ENABLED", "true").lower() == "true"
    LOCAL_LLM_URL: str = os.getenv("LLM_LOCAL_URL", "http://127.0.0.1:8081/v1/chat/completions")
    LOCAL_LLM_MODEL: str = os.getenv("LLM_LOCAL_MODEL", "local-model")
    REQUEST_TIMEOUT: int = int(os.getenv("REQUEST_TIMEOUT", "30"))
    # LLMé€Ÿåº¦/å“è³ªèª¿æ•´
    LLM_TEMPERATURE: float = float(os.getenv("LLM_TEMPERATURE", "0.3"))
    LLM_MAX_TOKENS: int = int(os.getenv("LLM_MAX_TOKENS", "200"))
    LLM_TOP_P: float = float(os.getenv("LLM_TOP_P", "0.9"))
    # å¤–éƒ¨Chat APIï¼ˆOpenAIäº’æ›ï¼‰è¨­å®šï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰
    PREFER_CHAT_API: bool = os.getenv("PREFER_CHAT_API", "true").lower() == "true"
    CHAT_API_BASE_URL: str = os.getenv("CHAT_API_BASE_URL", "")  # ä¾‹: http://localhost:8000/v1
    CHAT_API_KEY: str = os.getenv("CHAT_API_KEY", "")
    CHAT_API_MODEL: str = os.getenv("CHAT_API_MODEL", os.getenv("LLM_LOCAL_MODEL", "local-model"))
    # TTSï¼ˆä»»æ„ï¼‰
    ENABLE_TTS_PLAYBACK: bool = os.getenv("ENABLE_TTS_PLAYBACK", "false").lower() == "true"
    SERVER_TTS_URL: str = os.getenv("SERVER_TTS_URL", "")  # æœªæŒ‡å®šæ™‚ã¯ REMOTE_URL ã‹ã‚‰å°å‡º
    TTS_ENGINE: str = os.getenv("TTS_ENGINE", "")  # kokoro_onnx|kokoro_pt|piper|openjtalk ãªã©
    TTS_VOICE: str = os.getenv("TTS_VOICE", "")   # ä¾‹: jf_alpha
    TTS_SAMPLE_RATE: int = int(os.getenv("TTS_SAMPLE_RATE", "24000"))

# è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
audio_config = AudioConfig()
wake_config = WakeConfig()
vad_config = VADConfig()
server_config = ServerConfig()

# ========== Voskãƒ¢ãƒ‡ãƒ«ã¯ä½¿ç”¨ã—ã¾ã›ã‚“ï¼ˆsherpa-ONNXå°‚ç”¨ï¼‰ ==========

# ========== ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå‡¦ç† ==========
class AudioProcessor:
    def __init__(self):
        self.q = queue.Queue()
        self.vad = webrtcvad.Vad(vad_config.VAD_MODE)
        self.stream = None
        self._last_level_log = 0.0
        self.last_frame_time = time.time()
        self._squelch_until = 0.0  # å†ç”ŸéŸ³ã®å–ã‚Šè¾¼ã¿æŠ‘åˆ¶ç”¨
        # è§£æ±ºæ¸ˆã¿ãƒ‡ãƒã‚¤ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆNoneã§è‡ªå‹•ï¼‰
        self._resolved_input: Optional[int] = None
        self._resolved_output: Optional[int] = None

    def _device_index_by_name(self, name: str, require: str) -> Optional[int]:
        """åå‰ï¼ˆéƒ¨åˆ†ä¸€è‡´å¯ï¼‰ã¨æ–¹å‘('input'/'output')ã‹ã‚‰æœ€é©ãªãƒ‡ãƒã‚¤ã‚¹indexã‚’è¿”ã™ã€‚"""
        try:
            name_l = name.strip().lower()
            best = []
            for i, info in enumerate(sd.query_devices()):
                nm = str(info.get('name', '')).lower()
                if name_l in nm:
                    if require == 'input' and info.get('max_input_channels', 0) > 0:
                        best.append(i)
                    if require == 'output' and info.get('max_output_channels', 0) > 0:
                        best.append(i)
            return best[0] if best else None
        except Exception:
            return None

    def _resolve_input_device(self) -> Optional[int]:
        """å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ã‚’éå‰°ãªãƒãƒ³ãƒ‰ã‚ªãƒ•ãªã—ã«æ±ºå®šï¼ˆãƒ†ã‚¹ãƒˆã§å¤šé‡ã‚ªãƒ¼ãƒ—ãƒ³ã—ãªã„ï¼‰ã€‚"""
        # 1) æ˜ç¤ºæŒ‡å®šï¼ˆç•ªå· or åå‰ï¼‰
        val = audio_config.INPUT_DEVICE
        if val is not None and str(val).strip() != "":
            s = str(val).strip()
            if s.isdigit():
                try:
                    idx = int(s)
                    if sd.query_devices(idx).get('max_input_channels', 0) > 0:
                        return idx
                except Exception as e:
                    logger.warning(f"âš ï¸ æŒ‡å®šå…¥åŠ›indexç„¡åŠ¹: {s}: {e}")
            else:
                idx = self._device_index_by_name(s, 'input')
                if idx is not None:
                    return idx
                else:
                    try:
                        matches = [f"[{i}] {d['name']}" for i, d in enumerate(sd.query_devices()) if s.lower() in str(d.get('name','')).lower()]
                        if matches:
                            logger.warning(f"âš ï¸ æŒ‡å®šåã«è¤‡æ•°ä¸€è‡´: {s}: {', '.join(matches)}")
                    except Exception:
                        pass
        # 2) ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        try:
            di = sd.default.device[0]
            if di not in (-1, None) and sd.query_devices(di).get('max_input_channels', 0) > 0:
                return di
        except Exception:
            pass
        # 3) æœ€åˆã®å…¥åŠ›å¯èƒ½ãƒ‡ãƒã‚¤ã‚¹
        try:
            for i, info in enumerate(sd.query_devices()):
                if info.get('max_input_channels', 0) > 0:
                    return i
        except Exception:
            pass
        logger.warning("âŒ å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ã‚’æ±ºå®šã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return None

    def _resolve_output_device(self) -> Optional[int]:
        val = audio_config.OUTPUT_DEVICE
        if val is not None and str(val).strip() != "":
            s = str(val).strip()
            if s.isdigit():
                try:
                    idx = int(s)
                    if sd.query_devices(idx).get('max_output_channels', 0) > 0:
                        return idx
                except Exception:
                    pass
            else:
                idx = self._device_index_by_name(s, 'output')
                if idx is not None:
                    return idx
        try:
            do = sd.default.device[1]
            if do not in (-1, None) and sd.query_devices(do).get('max_output_channels', 0) > 0:
                return do
        except Exception:
            pass
        try:
            for i, info in enumerate(sd.query_devices()):
                if info.get('max_output_channels', 0) > 0:
                    return i
        except Exception:
            pass
        return None

    def _test_input_device_frames(self, device_id: int, sample_rate: int, timeout_s: float = 0.6) -> bool:
        """å®Ÿãƒ•ãƒ¬ãƒ¼ãƒ ãŒå±Šãã€ã‹ã¤ç„¡éŸ³ã‚¼ãƒ­ã§ã¯ãªã„ã‹ã‚’ç¢ºèªã™ã‚‹ã€‚"""
        try:
            from collections import deque
            got = deque(maxlen=20)
            frame_count = 0
            
            def cb(indata, frames, time_info, status):
                nonlocal frame_count
                frame_count += 1
                if status:
                    pass
                # ç°¡æ˜“RMSã§ç„¡éŸ³ã‚¼ãƒ­ã‚’åˆ¤å®š
                try:
                    import numpy as _np
                    rms = float(_np.sqrt(_np.mean((indata.astype(_np.float32) / 32768.0) ** 2)))
                except Exception:
                    rms = 0.0
                got.append(rms)
                
            block = max(1, int(sample_rate * audio_config.FRAME_DUR_MS / 1000))
            device_param = (device_id, None)
            s = sd.InputStream(
                channels=1,
                samplerate=sample_rate,
                dtype=audio_config.DTYPE,
                blocksize=block,
                device=device_param,
                callback=cb,
            )
            s.start()
            t0 = time.time()
            ok = False
            while time.time() - t0 < timeout_s:
                if got:
                    # æœ€ä½10ãƒ•ãƒ¬ãƒ¼ãƒ ã¯å—ä¿¡ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
                    if frame_count >= 10:
                        # ãƒ•ãƒ¬ãƒ¼ãƒ ã¯å±Šã„ã¦ã„ã‚‹ãŒã€å…¨ã¦å®Œå…¨ç„¡éŸ³(-inf dBFSç›¸å½“)ã‹ãƒã‚§ãƒƒã‚¯
                        max_rms = max(got) if got else 0.0
                        if max_rms > 1e-7:  # é–¾å€¤ã‚’å°‘ã—ä¸‹ã’ã¦ãƒ†ã‚¹ãƒˆ
                            ok = True
                            break
                        elif frame_count >= 20:
                            # 20ãƒ•ãƒ¬ãƒ¼ãƒ ä»¥ä¸Šå±Šã„ã¦ã„ã‚‹ãŒå…¨ã¦ç„¡éŸ³ â†’ æ©Ÿèƒ½ã—ãªã„ãƒ‡ãƒã‚¤ã‚¹
                            logger.debug(f"ãƒ‡ãƒã‚¤ã‚¹[{device_id}]: ãƒ•ãƒ¬ãƒ¼ãƒ ã¯å±ŠããŒå…¨ã¦ç„¡éŸ³ (max_rms={max_rms:.2e})")
                            break
                time.sleep(0.05)
            s.stop(); s.close()
            
            if frame_count == 0:
                logger.debug(f"ãƒ‡ãƒã‚¤ã‚¹[{device_id}]: ãƒ•ãƒ¬ãƒ¼ãƒ æœªå—ä¿¡")
            elif not ok and frame_count > 0:
                logger.debug(f"ãƒ‡ãƒã‚¤ã‚¹[{device_id}]: {frame_count}ãƒ•ãƒ¬ãƒ¼ãƒ å—ä¿¡ã€ä½†ã—ç„¡éŸ³ã®ã¿")
                
            return ok
        except Exception as e:
            logger.debug(f"ãƒ‡ãƒã‚¤ã‚¹[{device_id}]ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def _ensure_working_samplerate(self, device_id: int) -> int:
        """ç¾åœ¨ã®è¨­å®šã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆãŒåˆã‚ãªã„å ´åˆã« 16k â†’ 8k ã®é †ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚"""
        sr_try = [audio_config.SAMPLE_RATE]
        if 16000 not in sr_try:
            sr_try.append(16000)
        if 8000 not in sr_try:
            sr_try.append(8000)
        for sr in sr_try:
            if self._test_input_device_frames(device_id, sr, timeout_s=0.6):
                if sr != audio_config.SAMPLE_RATE:
                    logger.info(f"ğŸ› å…¥åŠ›ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã‚’ {audio_config.SAMPLE_RATE}Hz â†’ {sr}Hz ã«åˆ‡æ›¿")
                    audio_config.SAMPLE_RATE = sr
                return sr
        logger.warning("âš ï¸ ã„ãšã‚Œã®ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã§ã‚‚ãƒ•ãƒ¬ãƒ¼ãƒ æœªåˆ°é”ã€‚è¨­å®šå€¤ã‚’ç¶™ç¶šã—ã¾ã™ã€‚")
        return audio_config.SAMPLE_RATE
        
    def audio_callback(self, indata, frames, time_info, status):
        """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        if status:
            logger.warning(f"ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}")
        now = time.time()
        # å†ç”ŸéŸ³ãŒãƒã‚¤ã‚¯ã«å›ã‚Šè¾¼ã‚€ã®ã‚’æŠ‘åˆ¶ï¼ˆåŠäºŒé‡çš„ã«ç„¡è¦–ï¼‰
        if now < self._squelch_until:
            # å–ã‚Šè¾¼ã¾ãªã„ãŒã€æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ æ™‚åˆ»ã¯æ›´æ–°
            self.last_frame_time = now
            return
        self.q.put(indata.copy())
        self.last_frame_time = time.time()

    def squelch(self, duration_sec: float):
        """æŒ‡å®šæ™‚é–“ã€å…¥åŠ›ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç„¡è¦–ï¼ˆå†ç”ŸéŸ³ã®å›ã‚Šè¾¼ã¿å¯¾ç­–ï¼‰"""
        self._squelch_until = max(self._squelch_until, time.time() + max(0.0, duration_sec))
        
    def start_stream(self):
        """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹ (å®‰å®šç‰ˆ)"""
        if self.stream is None:
            # ãƒ‡ãƒã‚¤ã‚¹è§£æ±ºï¼ˆãƒ†ã‚¹ãƒˆé–‹é–‰ã¯è¡Œã‚ãªã„ç°¡æ½”ãªæ–¹å¼ï¼‰
            device_id = self._find_available_input_device()
            if device_id is None:
                logger.error("å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ€ãƒŸãƒ¼ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã—ã¾ã™ã€‚")
                self._start_dummy_stream()
                return
                
            try:
                self.stream = sd.InputStream(
                    channels=audio_config.CHANNELS,
                    samplerate=audio_config.SAMPLE_RATE,
                    dtype=audio_config.DTYPE,
                    blocksize=audio_config.frame_length,
                    device=device_id,
                    callback=self.audio_callback
                )
            except Exception as e:
                logger.error(f"ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ä½œæˆå¤±æ•—: {e}")
                self._start_dummy_stream()
                return
            try:
                self.stream.start()
            except Exception as e:
                logger.error(f"âŒ ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
                logger.error(f"   ãƒ‡ãƒã‚¤ã‚¹ {device_id} ã§ã‚¨ãƒ©ãƒ¼ã€‚ãƒ€ãƒŸãƒ¼ã‚¹ãƒˆãƒªãƒ¼ãƒ ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                self.stream = None
                self._start_dummy_stream()
                return
            # ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚’è¨˜éŒ²
            try:
                in_dev = sd.query_devices(device_id)
                logger.info(f"ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹ device='[{device_id}] {in_dev.get('name','unknown')}' samplerate={audio_config.SAMPLE_RATE}Hz block={audio_config.frame_length}")
            except Exception:
                logger.info("ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹")
    
    def stop_stream(self):
        """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢ (t-wada style robust implementation)"""
        if self.stream:
            if self.stream == "dummy":
                # ãƒ€ãƒŸãƒ¼ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®åœæ­¢
                self.stream = None
                logger.info("ğŸ”‡ ãƒ€ãƒŸãƒ¼ã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢")
            else:
                # é€šå¸¸ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢
                try:
                    self.stream.stop()
                    self.stream.close()
                except Exception as e:
                    logger.warning(f"âš ï¸ ã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢ã‚¨ãƒ©ãƒ¼: {e}")
                self.stream = None
                logger.info("ğŸ¤ ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢")
    
    def get_audio_frame(self, timeout: Optional[float] = None) -> Optional[np.ndarray]:
        """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—"""
        try:
            return self.q.get(timeout=timeout)
        except queue.Empty:
            return None
    
    def clear_queue(self):
        """ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢"""
        while not self.q.empty():
            try:
                self.q.get_nowait()
            except queue.Empty:
                break
    
    def _find_available_input_device(self) -> Optional[int]:
        """åˆ©ç”¨å¯èƒ½ãªå…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ã‚’æ¢ã™ï¼ˆåå‰ã§ã®é™¤å¤–ã¯è¡Œã‚ãšã€å®Ÿãƒ†ã‚¹ãƒˆã§åˆ¤å®šï¼‰"""
        try:
            devices = sd.query_devices()
            tested_indices = set()

            # 1) ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãŒã‚ã‚Œã°æœ€å„ªå…ˆã§ãƒ†ã‚¹ãƒˆ
            if audio_config.INPUT_DEVICE is not None:
                user_spec = str(audio_config.INPUT_DEVICE)
                
                # A) If it's a number, treat as device index
                if user_spec.isdigit():
                    try:
                        dev_idx = int(user_spec)
                        tested_indices.add(dev_idx)
                        info = sd.query_devices(dev_idx)
                        if info.get('max_input_channels', 0) > 0 and self._test_input_device(dev_idx):
                            logger.info(f"âœ… è¨­å®šã•ã‚ŒãŸå…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ä½¿ç”¨: [{dev_idx}] {info['name']}")
                            return dev_idx
                        else:
                            logger.warning(f"âš ï¸ è¨­å®šãƒ‡ãƒã‚¤ã‚¹IDX [{dev_idx}] ã¯å…¥åŠ›ä¸å¯ã¾ãŸã¯ãƒ†ã‚¹ãƒˆå¤±æ•—")
                    except Exception as e:
                        logger.warning(f"âš ï¸ è¨­å®šãƒ‡ãƒã‚¤ã‚¹IDX [{user_spec}] ã®ãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼: {e}")

                # B) If it's a string, search for matching device names
                else:
                    matching_devices = []
                    for i, info in enumerate(devices):
                        if user_spec.lower() in (info.get('name') or '').lower() and info.get('max_input_channels', 0) > 0:
                            matching_devices.append((i, info))
                    
                    if matching_devices:
                        logger.info(f"è¨­å®šå '{user_spec}' ã«ä¸€è‡´ã™ã‚‹ {len(matching_devices)} å€‹ã®ãƒ‡ãƒã‚¤ã‚¹ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™...")
                        for i, info in matching_devices:
                            tested_indices.add(i)
                            if self._test_input_device(i):
                                logger.info(f"âœ… è¨­å®šã•ã‚ŒãŸå…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ä½¿ç”¨: [{i}] {info['name']}")
                                return i
                        logger.warning(f"âš ï¸ è¨­å®šå '{user_spec}' ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒã‚¤ã‚¹ã¯å…¨ã¦ãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                    else:
                        logger.warning(f"âš ï¸ è¨­å®šå '{user_spec}' ã«ä¸€è‡´ã™ã‚‹å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            # 2) ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ã‚’ãƒ†ã‚¹ãƒˆ
            default_in = sd.default.device[0]
            if default_in not in (-1, None) and default_in not in tested_indices:
                tested_indices.add(default_in)
                try:
                    info = sd.query_devices(default_in)
                    if info.get('max_input_channels', 0) > 0 and self._test_input_device(default_in):
                        logger.info(f"âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ä½¿ç”¨: [{default_in}] {info['name']}")
                        return default_in
                    else:
                        logger.warning(f"âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ãƒ†ã‚¹ãƒˆå¤±æ•—: [{default_in}] {info.get('name','?')}")
                except Exception as e:
                    logger.warning(f"âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ä½¿ç”¨ä¸å¯: {e}")

            # 3) ä¸€è¦§ã‹ã‚‰å…¥åŠ›å¯èƒ½ãªãƒ‡ãƒã‚¤ã‚¹ã‚’é †ã«ãƒ†ã‚¹ãƒˆ
            for i, info in enumerate(devices):
                if i in tested_indices:
                    continue
                if info.get('max_input_channels', 0) > 0:
                    if self._test_input_device(i):
                        logger.info(f"âœ… ãƒ†ã‚¹ãƒˆæ¸ˆã¿å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ä½¿ç”¨: [{i}] {info.get('name','?')}")
                        return i
                    else:
                        logger.warning(f"âš ï¸ ãƒ‡ãƒã‚¤ã‚¹ãƒ†ã‚¹ãƒˆå¤±æ•—: [{i}] {info.get('name','?')}")

            logger.warning("âŒ å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return None

        except Exception as e:
            logger.error(f"âŒ ãƒ‡ãƒã‚¤ã‚¹æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _test_input_device(self, device_id: int) -> bool:
        """æŒ‡å®šã—ãŸãƒ‡ãƒã‚¤ã‚¹ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‹ãƒ†ã‚¹ãƒˆã™ã‚‹ (t-wada style)"""
        try:
            # çŸ­æ™‚é–“ã®ãƒ†ã‚¹ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä½œæˆã—ã¦é–‹å§‹/åœæ­¢
            test_stream = sd.InputStream(
                channels=1,  # ãƒ†ã‚¹ãƒˆç”¨ã¯1ãƒãƒ£ãƒ³ãƒãƒ«ã®ã¿
                samplerate=audio_config.SAMPLE_RATE,
                dtype=audio_config.DTYPE,
                blocksize=512,  # å°ã•ãªãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚ºã§ãƒ†ã‚¹ãƒˆ
                device=device_id,
                callback=lambda indata, frames, time, status: None  # ãƒ€ãƒŸãƒ¼ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
            )
            test_stream.start()
            time.sleep(0.1)  # 100ms å¾…æ©Ÿ
            test_stream.stop()
            test_stream.close()
            return True
        except Exception as e:
            logger.debug(f"ãƒ‡ãƒã‚¤ã‚¹ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ [{device_id}]: {e}")
            return False
    
    def _start_dummy_stream(self):
        """ãƒ€ãƒŸãƒ¼ã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹ (ãƒã‚¤ã‚¯ãŒç„¡ã„ç’°å¢ƒã§ã®ãƒ†ã‚¹ãƒˆç”¨)"""
        logger.info("ğŸ”‡ ãƒ€ãƒŸãƒ¼ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ï¼ˆãƒã‚¤ã‚¯å…¥åŠ›ç„¡ã—ï¼‰")
        self.stream = "dummy"  # ãƒ€ãƒŸãƒ¼ã‚¹ãƒˆãƒªãƒ¼ãƒ æŒ‡æ¨™
        # å®šæœŸçš„ã«ãƒ€ãƒŸãƒ¼éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹
        import threading
        def dummy_audio_generator():
            while self.stream == "dummy":
                # ç„¡éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
                dummy_frame = np.zeros((audio_config.frame_length, audio_config.CHANNELS), dtype=np.int16)
                self.q.put(dummy_frame)
                time.sleep(audio_config.FRAME_DUR_MS / 1000.0)
        
        self.dummy_thread = threading.Thread(target=dummy_audio_generator, daemon=True)
        self.dummy_thread.start()
        logger.info("ğŸ¤– ãƒ€ãƒŸãƒ¼éŸ³å£°ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé–‹å§‹")

# ========== Wake Wordæ¤œçŸ¥ï¼ˆsherpa-ONNXï¼‰ ==========


class SherpaWakeWordDetector:
    def __init__(self):
        try:
            import sherpa_onnx as so
        except Exception as e:
            raise RuntimeError(f"sherpa-onnx ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
        self.so = so
        self.text_history: List[Tuple[str, float]] = []
        self.last_text = ""
        self._last_decode_t = 0.0
        self._init_offline_recognizer()
        self._pcm_buffer = np.zeros(0, dtype=np.int16)

    def _env(self, name: str, default: Optional[str] = None) -> Optional[str]:
        # WAKE_SHERPA_* ã‚’å„ªå…ˆã€ãªã‘ã‚Œã° SHERPA_* ã‚’å‚ç…§
        return os.getenv(name) or os.getenv(name.replace("WAKE_", ""), default)

    def _init_offline_recognizer(self):
        so = self.so
        mt = (self._env("WAKE_SHERPA_MODEL_TYPE", "").strip().lower())
        if not mt:
            raise RuntimeError("WAKE_SHERPA_MODEL_TYPEï¼ˆã¾ãŸã¯SHERPA_MODEL_TYPEï¼‰ãŒæœªè¨­å®šã§ã™")
        tokens = self._env("WAKE_SHERPA_TOKENS")
        model = self._env("WAKE_SHERPA_MODEL")
        enc = self._env("WAKE_SHERPA_ENCODER")
        dec = self._env("WAKE_SHERPA_DECODER")
        join = self._env("WAKE_SHERPA_JOINER")
        num_threads = int(self._env("WAKE_SHERPA_NUM_THREADS", "1"))
        provider = self._env("WAKE_SHERPA_PROVIDER", "cpu")
        language = self._env("WAKE_SHERPA_LANGUAGE", "auto") or "auto"
        task = self._env("WAKE_SHERPA_TASK", "transcribe") or "transcribe"

        # Prefer Python wrapper classmethods first (sherpa-onnx >=1.10)
        OR = getattr(so, "OfflineRecognizer", None)
        if OR is None:
            raise RuntimeError("sherpa_onnx.OfflineRecognizer ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        try:
            if mt == "whisper" and hasattr(OR, "from_whisper"):
                if not (enc and dec):
                    raise RuntimeError("Whisperã®è¨­å®šä¸è¶³ï¼ˆENCODER/DECODERï¼‰")
                lang = language
                if (lang or "").lower() in {"", "auto", "autodetect", "auto_detect"}:
                    # sherpa-onnx whisper does not accept 'auto'; default to Japanese here.
                    lang = "ja"
                    logger.warning("Whisperè¨€èªãŒ'auto'ã®ãŸã‚'ja'ã«è¨­å®šã—ã¾ã—ãŸã€‚WAKE_SHERPA_LANGUAGEã§å¤‰æ›´ã§ãã¾ã™ã€‚")
                self.recognizer = OR.from_whisper(
                    encoder=enc,
                    decoder=dec,
                    tokens=tokens or "",
                    language=lang,
                    task=task,
                    num_threads=num_threads,
                    provider=provider,
                )
                return
            if mt == "paraformer" and hasattr(OR, "from_paraformer"):
                if not (model and tokens):
                    raise RuntimeError("Paraformerã®è¨­å®šä¸è¶³ï¼ˆMODEL/TOKENSï¼‰")
                self.recognizer = OR.from_paraformer(
                    paraformer=model,
                    tokens=tokens or "",
                    num_threads=num_threads,
                    provider=provider,
                )
                return
            if mt == "transducer" and hasattr(OR, "from_transducer"):
                if not (enc and dec and join and tokens):
                    raise RuntimeError("Transducerã®è¨­å®šä¸è¶³ï¼ˆENCODER/DECODER/JOINER/TOKENSï¼‰")
                self.recognizer = OR.from_transducer(
                    encoder=enc,
                    decoder=dec,
                    joiner=join,
                    tokens=tokens or "",
                    num_threads=num_threads,
                    provider=provider,
                )
                return
        except Exception:
            # Fall through to config-based initialization
            pass

        # Config-based initialization for other versions
        OfflineModelConfig = getattr(so, "OfflineModelConfig", None)
        if OfflineModelConfig is None:
            raise RuntimeError("sherpa_onnx.OfflineModelConfig ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        Para = getattr(so, "OfflineParaformerModelConfig", None)
        Trans = getattr(so, "OfflineTransducerModelConfig", None)
        Whisp = getattr(so, "OfflineWhisperModelConfig", None)

        kwargs = {
            "tokens": tokens or "",
            "num_threads": num_threads,
            "provider": provider,
        }
        if mt == "paraformer":
            if not (model and tokens and Para):
                raise RuntimeError("Paraformerã®è¨­å®šä¸è¶³ï¼ˆMODEL/TOKENSï¼‰")
            kwargs["paraformer"] = Para(model=model)
        elif mt == "transducer":
            if not (enc and dec and join and tokens and Trans):
                raise RuntimeError("Transducerã®è¨­å®šä¸è¶³ï¼ˆENCODER/DECODER/JOINER/TOKENSï¼‰")
            kwargs["transducer"] = Trans(encoder=enc, decoder=dec, joiner=join)
        else:  # whisper
            if not (enc and dec and Whisp):
                raise RuntimeError("Whisperã®è¨­å®šä¸è¶³ï¼ˆENCODER/DECODERï¼‰")
            try:
                kwargs["whisper"] = Whisp(encoder=enc, decoder=dec, language=language, task=task)
            except TypeError:
                kwargs["whisper"] = Whisp(encoder=enc, decoder=dec)

        OfflineRecognizer = getattr(so, "OfflineRecognizer")
        RecognizerCfg = getattr(so, "OfflineRecognizerConfig", None)
        ModelCfg = getattr(so, "OfflineModelConfig")
        decoding = os.getenv("WAKE_SHERPA_DECODING_METHOD", os.getenv("SHERPA_DECODING_METHOD", "greedy_search"))

        # Try 1: create_offline_recognizer/ from_config/ constructor patterns
        if RecognizerCfg is not None:
            rec_cfg = RecognizerCfg(model_config=ModelCfg(**kwargs), decoding_method=decoding)
            factory = getattr(so, "create_offline_recognizer", None)
            if factory is not None:
                try:
                    self.recognizer = factory(rec_cfg)  # type: ignore[misc]
                    return
                except Exception:
                    pass
            if hasattr(OfflineRecognizer, "from_config"):
                try:
                    self.recognizer = OfflineRecognizer.from_config(rec_cfg)  # type: ignore[attr-defined]
                    return
                except Exception:
                    pass
            try:
                # Some versions may accept calling via the wrapper
                self.recognizer = OfflineRecognizer(rec_cfg)
                return
            except TypeError:
                pass

        # Try 2: Pass model_config directly as kwargs
        try:
            self.recognizer = OfflineRecognizer(model_config=ModelCfg(**kwargs), decoding_method=decoding)
            return
        except TypeError:
            pass

        # Try 3: Legacy positional model config
        try:
            self.recognizer = OfflineRecognizer(ModelCfg(**kwargs))
            return
        except TypeError as e:
            raise RuntimeError("sherpa-onnx OfflineRecognizer ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚äº’æ›ã®ã‚ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¸å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚") from e

    def reset(self):
        self.text_history.clear()
        self.last_text = ""
        self._last_decode_t = 0.0
        self._pcm_buffer = np.zeros(0, dtype=np.int16)

    def process_audio(self, pcm_data: bytes) -> bool:
        # ãƒãƒƒãƒ•ã‚¡ã«è¿½è¨˜ã—ã€æœ€å¤§ã§ (WAKE_TIMEOUT_S + 0.5)s ã‚’ä¿æŒ
        pcm = np.frombuffer(pcm_data, dtype=np.int16)
        if pcm.size:
            self._pcm_buffer = np.concatenate([self._pcm_buffer, pcm])
            max_len = int((wake_config.WAKE_TIMEOUT_S + 0.5) * audio_config.SAMPLE_RATE)
            if self._pcm_buffer.size > max_len:
                self._pcm_buffer = self._pcm_buffer[-max_len:]

        now = time.time()
        # ãƒ‡ã‚³ãƒ¼ãƒ‰ã¯700msé–“éš”ã§å®Ÿè¡Œï¼ˆè² è·æŠ‘åˆ¶ï¼‰
        if now - self._last_decode_t >= 0.7 and self._pcm_buffer.size > 0:
            # int16 -> float32 [-1,1]
            f32 = (self._pcm_buffer.astype(np.float32) / 32768.0).copy()
            stream = self.recognizer.create_stream()
            stream.accept_waveform(audio_config.SAMPLE_RATE, f32)
            self.recognizer.decode_stream(stream)
            text = getattr(stream.result, "text", "") or ""
            if text and text != self.last_text:
                if logger.isEnabledFor(logging.DEBUG) or os.getenv("WAKE_DEBUG_PARTIAL", "").lower() in {"1","true","yes","on"}:
                    logger.debug(f"Wake partial: {text}")
                self.text_history.append((text, now))
                self.last_text = text
            self._last_decode_t = now

        cutoff_time = now - wake_config.WAKE_TIMEOUT_S - 0.5
        self.text_history = [(t, ts) for t, ts in self.text_history if ts >= cutoff_time]
        return self._check_wake_words()

    def _check_wake_words(self) -> bool:
        current_time = time.time()
        recent_text = recent_text_from_history(self.text_history, current_time, wake_config.WAKE_TIMEOUT_S)
        ok = is_wake_in_text(recent_text, require_both=wake_config.WAKE_REQUIRE_BOTH)
        if ok:
            logger.info(f"Wake Wordæ¤œå‡º: {squash_repeated_tokens(recent_text)}")
        return ok

# ========== éŸ³å£°éŒ²éŸ³ ==========
class SpeechRecorder:
    def __init__(self, audio_processor: AudioProcessor):
        self.audio_processor = audio_processor
        
    def record_speech(self) -> np.ndarray:
        """VADã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’éŒ²éŸ³"""
        logger.info("éŒ²éŸ³é–‹å§‹...")
        
        speech_frames = []
        voiced_ms = 0
        silence_ms = 0
        started = False
        started_at = None  # type: Optional[float]
        
        start_time = time.time()
        
        while True:
            # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
            pcm = self.audio_processor.get_audio_frame(timeout=1.0)
            if pcm is None:
                continue
            
            # VADåˆ¤å®š
            is_speech = self.audio_processor.vad.is_speech(
                pcm.tobytes(),
                audio_config.SAMPLE_RATE
            )
            
            speech_frames.append(pcm)
            
            if is_speech:
                voiced_ms += audio_config.FRAME_DUR_MS
                silence_ms = 0
                if not started and voiced_ms >= vad_config.MIN_UTTERANCE_MS:
                    started = True
                    started_at = time.time()
                    logger.info("ç™ºè©±é–‹å§‹æ¤œå‡º")
            else:
                if started:
                    silence_ms += audio_config.FRAME_DUR_MS
            
            # çµ‚äº†æ¡ä»¶
            if started and silence_ms >= vad_config.END_SILENCE_MS:
                # ç™ºè©±é–‹å§‹ç›´å¾Œã¯æ—©æœŸçµ‚äº†ã‚’æŠ‘åˆ¶
                if started_at is not None:
                    elapsed_ms = int((time.time() - started_at) * 1000)
                    if elapsed_ms < vad_config.HOLD_AFTER_START_MS:
                        continue
                logger.info(f"ç™ºè©±çµ‚äº†æ¤œå‡º (ç„¡éŸ³ {silence_ms}ms)")
                break
            
            # æœ€å¤§éŒ²éŸ³æ™‚é–“
            if len(speech_frames) * audio_config.FRAME_DUR_MS > vad_config.MAX_RECORDING_MS:
                logger.warning("æœ€å¤§éŒ²éŸ³æ™‚é–“ã«åˆ°é”")
                break
            
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç™ºè©±ãŒå§‹ã¾ã‚‰ãªã„å ´åˆï¼‰
            if not started and (time.time() - start_time) > 5.0:
                logger.warning("ç™ºè©±ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                break
        
        if speech_frames:
            return np.concatenate(speech_frames, axis=0).reshape(-1)
        return np.array([], dtype=audio_config.DTYPE)

# ========== éŸ³å£°å‡¦ç† ==========
def save_wav(pcm_data: np.ndarray, filepath: str):
    """PCMãƒ‡ãƒ¼ã‚¿ã‚’WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
    with wave.open(filepath, 'wb') as wf:
        wf.setnchannels(audio_config.CHANNELS)
        wf.setsampwidth(2)  # int16
        wf.setframerate(audio_config.SAMPLE_RATE)
        wf.writeframes(pcm_data.tobytes())

def _dbfs(pcm: np.ndarray) -> float:
    """ç°¡æ˜“dBFSè¨ˆç®— (int16æƒ³å®š)"""
    if pcm.size == 0:
        return float("-inf")
    # 16-bit full scale
    rms = np.sqrt(np.mean((pcm.astype(np.float32) / 32768.0) ** 2))
    if rms <= 1e-8:
        return float("-inf")
    return 20.0 * np.log10(rms)

# ========== ã‚ªãƒ•ãƒ©ã‚¤ãƒ³STT ==========
def stt_offline_vosk(pcm_data: np.ndarray) -> str:
    """Voskã‚’ä½¿ç”¨ã—ãŸã‚ªãƒ•ãƒ©ã‚¤ãƒ³éŸ³å£°èªè­˜"""
    logger.info("ã‚ªãƒ•ãƒ©ã‚¤ãƒ³STTå‡¦ç†ä¸­...")
    
    recognizer = vosk.KaldiRecognizer(vosk_model, audio_config.SAMPLE_RATE)
    recognizer.SetWords(True)
    
    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
    recognizer.AcceptWaveform(pcm_data.tobytes())
    result = json.loads(recognizer.FinalResult())
    
    text = result.get("text", "").strip()
    logger.info(f"ã‚ªãƒ•ãƒ©ã‚¤ãƒ³STTçµæœ: {text}")
    return text

# ========== ä¾¿åˆ©é–¢æ•°ï¼ˆé€šçŸ¥éŸ³ï¼‰ ==========
def _fade_in_out(signal: np.ndarray, fade_ratio: float = 0.05) -> np.ndarray:
    n = len(signal)
    if n == 0:
        return signal
    fr = max(1, int(n * fade_ratio))
    window = np.ones(n, dtype=np.float32)
    window[:fr] = np.linspace(0.0, 1.0, fr, dtype=np.float32)
    window[-fr:] = np.linspace(1.0, 0.0, fr, dtype=np.float32)
    return (signal * window).astype(np.float32)

def play_wake_sound(audio_processor: Optional[AudioProcessor] = None):
    """ç°¡å˜ãªäºŒéŸ³ã€ãƒãƒ­ãƒ³ã€é€šçŸ¥éŸ³ã‚’å†ç”Ÿ"""
    try:
        sr = audio_config.SAMPLE_RATE
        # 880Hz -> 660Hz ã®äºŒéŸ³ï¼ˆå„90msï¼‰
        dur1 = 0.09
        dur2 = 0.09
        t1 = np.linspace(0, dur1, int(sr * dur1), endpoint=False)
        t2 = np.linspace(0, dur2, int(sr * dur2), endpoint=False)
        tone1 = 0.2 * np.sin(2 * np.pi * 880 * t1).astype(np.float32)
        tone2 = 0.2 * np.sin(2 * np.pi * 660 * t2).astype(np.float32)
        signal = np.concatenate([_fade_in_out(tone1), _fade_in_out(tone2)])
        # å‡ºåŠ›ãƒ‡ãƒã‚¤ã‚¹ã¯è§£æ±ºæ¸ˆã¿ãŒã‚ã‚Œã°å„ªå…ˆ
        dev_param = None
        if audio_processor is not None:
            dev_param = audio_processor._resolved_output
        dev = audio_config.OUTPUT_DEVICE
        if dev_param is None and isinstance(dev, str) and dev.isdigit():
            dev_param = int(dev)
        try:
            sd.play(signal, samplerate=sr, device=dev_param, blocking=True)
        except Exception:
            # ãƒ‡ãƒã‚¤ã‚¹å/ç•ªå·ãŒä¸æ­£ãªå ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‡ºåŠ›ã§å†è©¦è¡Œ
            sd.play(signal, samplerate=sr, blocking=True)
    except Exception as e:
        logger.warning(f"é€šçŸ¥éŸ³ã®å†ç”Ÿã«å¤±æ•—: {e}")

    

# ========== ã‚ªãƒ•ãƒ©ã‚¤ãƒ³LLM ==========
def llm_local_reply(prompt: str, interaction_id: str = "") -> str:
    """ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’ä½¿ç”¨ã—ãŸå¿œç­”ç”Ÿæˆ"""
    logger.info("ãƒ­ãƒ¼ã‚«ãƒ«LLMå‡¦ç†ä¸­...")
    
    payload = {
        "model": server_config.LOCAL_LLM_MODEL,
        "messages": [
            {
                "role": "system",
                "content": "ã‚ãªãŸã¯ã€Œã‚µã‚¤ãƒ†ã‚¯ã€ã¨ã„ã†åå‰ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã§ç°¡æ½”ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "temperature": server_config.LLM_TEMPERATURE,
        "max_tokens": server_config.LLM_MAX_TOKENS,
        "top_p": server_config.LLM_TOP_P
    }
    
    try:
        response = requests.post(
            server_config.LOCAL_LLM_URL,
            json=payload,
            headers={"X-Interaction-ID": interaction_id} if interaction_id else None,
            timeout=server_config.REQUEST_TIMEOUT
        )
        response.raise_for_status()
        
        result = response.json()
        reply = result["choices"][0]["message"]["content"]
        logger.info(f"ãƒ­ãƒ¼ã‚«ãƒ«LLMå¿œç­”: {reply[:50]}...")
        return reply
        
    except Exception as e:
        logger.error(f"ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚¨ãƒ©ãƒ¼: {e}")
        return f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å¿œç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å…¥åŠ›: {prompt}"

def llm_streaming_chat_api(prompt: str, interaction_id: str = "") -> str:
    """å¤–éƒ¨Chat APIï¼ˆOpenAIäº’æ›ï¼‰ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å¿œç­”ã‚’å–å¾—ã—ã¦é€æ¬¡è¡¨ç¤ºã™ã‚‹ã€‚
    åˆ©ç”¨æ¡ä»¶: CHAT_API_BASE_URL, CHAT_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã€‚
    å¤±æ•—æ™‚ã¯ä¾‹å¤–ã‚’æŠ•ã’ã‚‹ï¼ˆå‘¼ã³å‡ºã—å´ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ã€‚
    """
    if not server_config.CHAT_API_BASE_URL or not server_config.CHAT_API_KEY:
        raise RuntimeError("Chat APIè¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™")

    base = server_config.CHAT_API_BASE_URL.rstrip("/")
    def build_url(b: str, path: str = "/chat/completions") -> str:
        return b.rstrip("/") + path
    url = build_url(base, "/chat/completions")
    headers = {
        "Authorization": f"Bearer {server_config.CHAT_API_KEY}",
        "Content-Type": "application/json",
    }
    if interaction_id:
        headers["X-Interaction-ID"] = interaction_id

    payload = {
        "model": server_config.CHAT_API_MODEL,
        "messages": [
            {"role": "system", "content": "ã‚ãªãŸã¯ã€ã‚µã‚¤ãƒ†ã‚¯ã€ã¨ã„ã†ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã§ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚"},
            {"role": "user", "content": prompt},
        ],
        "temperature": server_config.LLM_TEMPERATURE,
        "max_tokens": server_config.LLM_MAX_TOKENS,
        "top_p": server_config.LLM_TOP_P,
        "stream": True,
    }

    print("ğŸŒ€ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”: ", end="", flush=True)
    full = []
    def stream_once(u: str) -> None:
        with requests.post(u, json=payload, headers=headers, stream=True, timeout=(5, server_config.REQUEST_TIMEOUT)) as r:
            r.raise_for_status()
            for raw in r.iter_lines(decode_unicode=True):
                if raw is None or raw == "":
                    continue
                line = raw.strip()
                if not line.startswith("data:"):
                    continue
                data = line[5:].strip()
                if data == "[DONE]":
                    break
                try:
                    obj = json.loads(data)
                except Exception:
                    continue
                choices = obj.get("choices") or []
                if not choices:
                    continue
                delta = choices[0].get("delta") or {}
                piece = delta.get("content")
                if piece is None:
                    piece = choices[0].get("text")
                if not piece:
                    continue
                print(piece, end="", flush=True)
                full.append(piece)

    tried_alt = False
    try:
        stream_once(url)
    except requests.HTTPError as http_err:
        status = getattr(http_err.response, 'status_code', None)
        # 404/405ãªã©ã®å ´åˆã€/v1 ã®æœ‰ç„¡ã‚’åˆ‡ã‚Šæ›¿ãˆã¦å†è©¦è¡Œ
        if status in (404, 405):
            tried_alt = True
            base2 = base
            if base2.rstrip('/').endswith('/v1'):
                base2 = base2.rstrip('/').rsplit('/v1', 1)[0]
            else:
                base2 = base2.rstrip('/') + '/v1'
            alt_url = build_url(base2, "/chat/completions")
            logger.warning(f"Chat API 404/405: {status}. åˆ¥ãƒ‘ã‚¹ã§å†è©¦è¡Œ: {alt_url}")
            try:
                stream_once(alt_url)
            except requests.HTTPError as http_err2:
                status2 = getattr(http_err2.response, 'status_code', None)
                # ã¾ã ãƒ€ãƒ¡ãªã‚‰ /responses ã‚‚è©¦ã™
                alt2 = build_url(base, "/responses")
                logger.warning(f"Chat API å†è©¦è¡Œå¤±æ•—: {status2}. ä»£æ›¿ãƒ‘ã‚¹ã§å†è©¦è¡Œ: {alt2}")
                stream_once(alt2)
        else:
            raise
    finally:
        print()
    reply = "".join(full).strip()
    logger.info(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­” çµ‚äº† len={len(reply)}")
    return reply

# ========== ã‚µãƒ¼ãƒãƒ¼é€šä¿¡ ==========
def _toggle_inference_path(url: str) -> str:
    """Toggle between legacy '/inference' and '/v1/audio/inference' on the same host."""
    try:
        from urllib.parse import urlparse, urlunparse
        u = urlparse(url)
        path = u.path.rstrip('/')
        if path.endswith('/v1/audio/inference'):
            path = path[: -len('/v1/audio/inference')] + '/inference'
        elif path.endswith('/inference'):
            path = path[: -len('/inference')] + '/v1/audio/inference'
        else:
            # If ambiguous, prefer v1
            if not path.endswith('/v1'):
                path = path + '/v1/audio/inference'
            else:
                path = path + '/audio/inference'
        return urlunparse((u.scheme, u.netloc, path, "", "", ""))
    except Exception:
        # Fallback string manipulation
        if '/v1/audio/inference' in url:
            return url.replace('/v1/audio/inference', '/inference')
        if url.endswith('/inference'):
            return url[:-len('/inference')] + '/v1/audio/inference'
        return url.rstrip('/') + '/v1/audio/inference'


def _iter_candidate_urls() -> List[str]:
    urls: List[str] = []
    mode = server_config.SERVER_API_MODE
    primary = server_config.REMOTE_URL.strip()
    alt_env = server_config.ALT_URL.strip()
    if primary:
        urls.append(primary)
        if mode == 'auto':
            urls.append(_toggle_inference_path(primary))
    if alt_env:
        if alt_env not in urls:
            urls.append(alt_env)
        if mode == 'auto':
            toggled = _toggle_inference_path(alt_env)
            if toggled not in urls:
                urls.append(toggled)
    # Deduplicate while preserving order
    seen = set()
    uniq: List[str] = []
    for u in urls:
        if u and u not in seen:
            uniq.append(u)
            seen.add(u)
    return uniq


def send_to_server(audio_data: np.ndarray, interaction_id: str) -> Tuple[bool, Optional[dict]]:
    """
    éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡
    
    Returns:
        (æˆåŠŸãƒ•ãƒ©ã‚°, ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿)
    """
    candidates = _iter_candidate_urls()
    logger.info(f"ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡ä¸­: {candidates[0]} (å€™è£œ={len(candidates)})")
    
    # ä¸€æ™‚WAVãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
        tmp_path = tmp_file.name
    
    try:
        save_wav(audio_data, tmp_path)
        
        last_err: Optional[Exception] = None
        for url in candidates:
            try:
                with open(tmp_path, "rb") as f:
                    files = {"file": ("utterance.wav", f, "audio/wav")}
                    response = requests.post(
                        url,
                        files=files,
                        headers={
                            "X-Interaction-ID": interaction_id,
                            "User-Agent": "WakeSaitekuClient/1.0"
                        },
                        timeout=server_config.REQUEST_TIMEOUT
                    )
                response.raise_for_status()
                data = response.json()
                logger.info(f"ã‚µãƒ¼ãƒãƒ¼å¿œç­”å—ä¿¡æˆåŠŸ url={url}")
                return True, data
            except requests.exceptions.Timeout as e:
                logger.warning(f"ã‚µãƒ¼ãƒãƒ¼ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ url={url}")
                last_err = e
                continue
            except requests.exceptions.ConnectionError as e:
                logger.warning(f"ã‚µãƒ¼ãƒãƒ¼æ¥ç¶šã‚¨ãƒ©ãƒ¼ url={url}")
                last_err = e
                continue
            except requests.HTTPError as e:
                status = getattr(getattr(e, 'response', None), 'status_code', None)
                logger.warning(f"HTTPã‚¨ãƒ©ãƒ¼ url={url} status={status}")
                last_err = e
                # try next candidate on 404/405/422 etc.
                continue
            except Exception as e:
                logger.warning(f"ã‚µãƒ¼ãƒãƒ¼é€šä¿¡ä¾‹å¤– url={url} err={e}")
                last_err = e
                continue
        # All candidates failed
        if last_err:
            logger.error(f"å…¨URLå¤±æ•—: {last_err}")
        return False, None
        
    except Exception as e:
        logger.error(f"ã‚µãƒ¼ãƒãƒ¼é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        return False, None
        
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        if os.path.exists(tmp_path):
            try:
                os.remove(tmp_path)
            except Exception as e:
                logger.warning(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")


# ========== ã‚µãƒ¼ãƒãƒ¼TTSå†ç”Ÿï¼ˆä»»æ„ï¼‰ ==========
def _derive_tts_url_from_inference(inf_url: str) -> str:
    try:
        from urllib.parse import urlparse, urlunparse
        u = urlparse(inf_url)
        # /inference ã‚’ /tts ã«
        path = u.path
        if path.endswith("/inference"):
            path = path[: -len("/inference")] + "/tts"
        else:
            if not path.endswith("/"):
                path = path + "/"
            path = path + "tts"
        return urlunparse((u.scheme, u.netloc, path, "", "", ""))
    except Exception:
        return inf_url.replace("/inference", "/tts")


def speak_via_server_tts(text: str, audio_processor: AudioProcessor) -> None:
    if not text:
        return
    tts_url = server_config.SERVER_TTS_URL.strip() or _derive_tts_url_from_inference(server_config.REMOTE_URL)
    try:
        logger.info(f"ã‚µãƒ¼ãƒãƒ¼TTSè¦æ±‚: {tts_url}")
        payload = {"text": text}
        if server_config.TTS_ENGINE:
            payload["engine"] = server_config.TTS_ENGINE
        if server_config.TTS_VOICE:
            payload["voice"] = server_config.TTS_VOICE
        if server_config.TTS_SAMPLE_RATE:
            payload["sample_rate"] = int(server_config.TTS_SAMPLE_RATE)
        r = requests.post(tts_url, json=payload, timeout=server_config.REQUEST_TIMEOUT)
        if r.status_code != 200 or (r.headers.get("Content-Type") or "").split(";")[0] != "audio/wav":
            logger.warning(f"ã‚µãƒ¼ãƒãƒ¼TTSå¤±æ•— status={r.status_code} content-type={r.headers.get('Content-Type')}")
            return
        data = r.content
        # WAVã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
        import io as _io
        import wave as _wave

        with _wave.open(_io.BytesIO(data), "rb") as wf:
            ch = wf.getnchannels()
            sr = wf.getframerate()
            sw = wf.getsampwidth()
            n = wf.getnframes()
            raw = wf.readframes(n)
        if sw != 2:
            logger.warning(f"TTS WAV ã‚µãƒ³ãƒ—ãƒ«å¹…ãŒæƒ³å®šå¤–: {sw}bytes")
            return
        # int16 -> float32 [-1,1]
        pcm = np.frombuffer(raw, dtype=np.int16)
        if ch > 1:
            pcm = pcm.reshape(-1, ch).mean(axis=1).astype(np.int16, copy=False)
        audio = (pcm.astype(np.float32) / 32767.0).astype(np.float32, copy=False)
        dur = len(audio) / float(sr or audio_config.SAMPLE_RATE)
        # å†ç”ŸéŸ³ã®å›ã‚Šè¾¼ã¿æŠ‘åˆ¶
        audio_processor.squelch(dur + 0.2)
        # è§£æ±ºæ¸ˆã¿ã®å‡ºåŠ›ãƒ‡ãƒã‚¤ã‚¹ã‚’å„ªå…ˆ
        dev_param = audio_processor._resolved_output
        if dev_param is None:
            dev = audio_config.OUTPUT_DEVICE
            if isinstance(dev, str) and dev.isdigit():
                dev_param = int(dev)
        try:
            sd.play(audio, samplerate=sr, device=dev_param, blocking=False)
        except Exception:
            sd.play(audio, samplerate=sr, blocking=False)
        logger.info(f"ã‚µãƒ¼ãƒãƒ¼TTSå†ç”Ÿ len={len(audio)} sr={sr} dur={dur:.2f}s")
    except Exception as e:
        logger.warning(f"ã‚µãƒ¼ãƒãƒ¼TTSå†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")

# ========== ãƒ¡ã‚¤ãƒ³å‡¦ç† ==========
def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
    print("\n" + "="*50)
    print("Wake Saiteku ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ")
    print("="*50)
    print(f"ğŸ™  Wake Wordå¾…æ©Ÿä¸­: ã€Œã‚‚ã—ã‚‚ã—ã‚µã‚¤ãƒ†ã‚¯ã€")
    print(f"ğŸ“¡ ã‚µãƒ¼ãƒãƒ¼: {server_config.REMOTE_URL}")
    print(f"ğŸ”§ ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if server_config.LOCAL_STT_ENABLED else 'ç„¡åŠ¹'}")
    logger.info(
        f"è¨­å®š: REMOTE_URL={server_config.REMOTE_URL}, LOCAL_STT_ENABLED={server_config.LOCAL_STT_ENABLED}, "
        f"LOCAL_LLM_URL={server_config.LOCAL_LLM_URL}, REQUEST_TIMEOUT={server_config.REQUEST_TIMEOUT}s, "
        f"PREFER_CHAT_API={server_config.PREFER_CHAT_API}, CHAT_API_BASE_URL={server_config.CHAT_API_BASE_URL or '-'}"
    )
    print("="*50 + "\n")
    
    # t-wada style TTSç–é€šãƒ†ã‚¹ãƒˆ
    if server_config.ENABLE_TTS_PLAYBACK and os.getenv("TTS_STARTUP_TEST", "true").lower() == "true":
        print("ğŸ”Š TTSç–é€šãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        try:
            test_text = "Wake Saitekuã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆèµ·å‹•å®Œäº†ã€‚TTSãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚"
            tts_url = server_config.SERVER_TTS_URL
            payload = {"text": test_text}
            if server_config.TTS_ENGINE:
                payload["engine"] = server_config.TTS_ENGINE
            if server_config.TTS_SAMPLE_RATE:
                payload["sample_rate"] = int(server_config.TTS_SAMPLE_RATE)
            
            r = requests.post(tts_url, json=payload, timeout=5)
            if r.status_code == 200 and (r.headers.get("Content-Type") or "").split(";")[0] == "audio/wav":
                print("âœ… TTSã‚µãƒ¼ãƒãƒ¼æ¥ç¶šæˆåŠŸ")
                # éŸ³å£°å†ç”Ÿãƒ†ã‚¹ãƒˆ
                import io as _io
                import wave as _wave
                with _wave.open(_io.BytesIO(r.content), "rb") as wf:
                    audio = np.frombuffer(wf.readframes(wf.getnframes()), dtype=np.int16).astype(np.float32) / 32767.0
                    dev = audio_config.OUTPUT_DEVICE
                    dev_param = int(dev) if isinstance(dev, str) and dev.isdigit() else dev
                    try:
                        sd.play(audio, samplerate=wf.getframerate(), device=dev_param, blocking=False)
                    except Exception:
                        sd.play(audio, samplerate=wf.getframerate(), blocking=False)
                    logger.info("âœ… TTSåˆæœŸåŒ–ãƒ†ã‚¹ãƒˆå®Œäº†")
                    time.sleep(1)  # éŸ³å£°å†ç”Ÿå¾…æ©Ÿ
            else:
                logger.warning(f"âš ï¸ TTSãƒ†ã‚¹ãƒˆå¤±æ•—: status={r.status_code}")
        except Exception as e:
            logger.warning(f"âš ï¸ TTSãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ (ç¶šè¡Œå¯èƒ½): {e}")
    
    # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–
    audio_processor = AudioProcessor()
    # Wakeæ¤œå‡ºå™¨ï¼ˆsherpaå°‚ç”¨ï¼‰
    try:
        wake_detector = SherpaWakeWordDetector()
        logger.info("Wakeãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰: SherpaWakeWordDetector")
    except Exception as e:
        logger.error(f"sherpaã®WakeåˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        logger.error(".envã® WAKE_SHERPA_* è¨­å®šã¨ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
        sys.exit(1)
    speech_recorder = SpeechRecorder(audio_processor)
    
    # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
    audio_processor.start_stream()
    # ãƒ­ãƒ¼ã‚«ãƒ«STTã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆsherpaå°‚ç”¨ï¼‰
    stt_backend = os.getenv("LOCAL_STT_BACKEND", "sherpa")
    try:
        local_stt = create_local_stt_engine(stt_backend, None)
        stt_name = local_stt.__class__.__name__
        logger.info(f"ãƒ­ãƒ¼ã‚«ãƒ«STTãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰: {stt_name}")
    except Exception as e:
        logger.error(f"ãƒ­ãƒ¼ã‚«ãƒ«STTåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(".env ã® SHERPA_* è¨­å®šã¨ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
        sys.exit(1)
    
    # ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰æ–¹å¼: ã‚­ãƒ¼å…¥åŠ›ã§ãƒã‚¤ã‚¯ä¸€æ™‚æœ‰åŠ¹åŒ–
    print("\nğŸ¤ ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹æœ€å°åŒ–ãƒ¢ãƒ¼ãƒ‰")
    print("   ã‚¹ãƒšãƒ¼ã‚¹ã‚­ãƒ¼ã‚’æŠ¼ã—ã¦Wake Wordæ¤œå‡ºã‚’é–‹å§‹")
    print("   'q' + Enter ã§çµ‚äº†")
    print("   ã¾ãŸã¯ç’°å¢ƒå¤‰æ•° ALWAYS_LISTEN=true ã§å¾“æ¥ãƒ¢ãƒ¼ãƒ‰")
    
    always_listen = os.getenv("ALWAYS_LISTEN", "false").lower() == "true"
    
    if always_listen:
        print("\nâš ï¸ å¸¸æ™‚ãƒªã‚¹ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ (ãƒã‚¤ã‚¯å¸¸æ™‚ã‚ªãƒ³)")
        # å¾“æ¥ã®å¸¸æ™‚ãƒªã‚¹ãƒ‹ãƒ³ã‚°
        run_traditional_mode(audio_processor, wake_detector, speech_recorder)
    else:
        print("\nâœ… ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ãƒ¢ãƒ¼ãƒ‰ (ã‚­ãƒ¼æ“ä½œã§ã®ã¿ãƒã‚¤ã‚¯æœ‰åŠ¹åŒ–)")
        run_ondemand_mode(audio_processor, wake_detector, speech_recorder)


def run_ondemand_mode(audio_processor, wake_detector, speech_recorder):
    """ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰æ–¹å¼: ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã§ã®ã¿ãƒã‚¤ã‚¯ã‚’æœ‰åŠ¹åŒ–"""
    import threading
    import sys
    import select
    
    print("\næ“ä½œæ–¹æ³•:")
    print("  [ã‚¹ãƒšãƒ¼ã‚¹] Wake Wordæ¤œå‡ºé–‹å§‹ (10ç§’é–“)")
    print("  [Enter] ç›´æ¥éŸ³å£°éŒ²éŸ³é–‹å§‹")  
    print("  [q] çµ‚äº†")
    
    def get_key_input():
        """ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã‚’å–å¾— (ãƒãƒ³ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°)"""
        if sys.stdin in select.select([sys.stdin], [], [], 0)[0]:
            return sys.stdin.read(1)
        return None
    
    try:
        while True:
            print("\nğŸ¤ å¾…æ©Ÿä¸­ (ãƒã‚¤ã‚¯ã‚ªãƒ•) - ã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„...")
            
            # ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›å¾…æ©Ÿ
            while True:
                try:
                    key = input().strip().lower()
                    if key == 'q':
                        return
                    elif key == '' or key == ' ':
                        # ã‚¹ãƒšãƒ¼ã‚¹ã¾ãŸã¯Enterã§Wake Wordæ¤œå‡º
                        perform_voice_interaction(audio_processor, wake_detector, speech_recorder)
                        break
                except KeyboardInterrupt:
                    return
                except EOFError:
                    return
                    
    except KeyboardInterrupt:
        print("\nğŸ‘‹ çµ‚äº†ã—ã¾ã™...")


def perform_voice_interaction(audio_processor, wake_detector, speech_recorder):
    """éŸ³å£°ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ (ãƒã‚¤ã‚¯ä¸€æ™‚æœ‰åŠ¹åŒ–)"""
    interaction_id = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ") + "-" + uuid.uuid4().hex[:8]
    
    try:
        print("ğŸ¤ ãƒã‚¤ã‚¯æœ‰åŠ¹åŒ–ä¸­...")
        audio_processor.start_stream()
        time.sleep(0.5)  # ã‚¹ãƒˆãƒªãƒ¼ãƒ å®‰å®šåŒ–å¾…æ©Ÿ
        
        print("ğŸ“¢ ãŠè©±ã—ãã ã•ã„... (5ç§’é–“éŒ²éŸ³)")
        
        # ç›´æ¥éŒ²éŸ³é–‹å§‹
        rec_start = time.perf_counter()
        audio_data = speech_recorder.record_speech()
        rec_dur = time.perf_counter() - rec_start
        
        if len(audio_data) == 0:
            print("âš ï¸ éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return
            
        print(f"ğŸ“¦ éŒ²éŸ³å®Œäº† ({len(audio_data) / audio_config.SAMPLE_RATE:.1f}ç§’)")
        
        # ã‚µãƒ¼ãƒãƒ¼é€ä¿¡ã¾ãŸã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‡¦ç†
        success, response = send_to_server(audio_data, interaction_id)
        
        if success and response:
            transcript = response.get("transcript", "")
            reply = response.get("reply", "")
            print(f"ğŸ“ èªè­˜: {transcript}")
            print(f"ğŸ¤– å¿œç­”: {reply}")
            
            # TTSå†ç”Ÿ
            if server_config.ENABLE_TTS_PLAYBACK and reply:
                speak_via_server_tts(reply, audio_processor)
        else:
            print("âŒ å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
    finally:
        print("ğŸ¤ ãƒã‚¤ã‚¯ç„¡åŠ¹åŒ–")
        audio_processor.stop_stream()


def run_traditional_mode(audio_processor, wake_detector, speech_recorder):
    """å¾“æ¥ã®å¸¸æ™‚ãƒªã‚¹ãƒ‹ãƒ³ã‚°æ–¹å¼"""
    print("âš ï¸ ã“ã®æ©Ÿèƒ½ã¯ç¾åœ¨åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰ãƒ¢ãƒ¼ãƒ‰ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚")


if __name__ == "__main__":
    main()
            
            # å°‘ã—å¾…ã£ã¦ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢ï¼ˆWake Wordã®æ®‹éŸ¿ã‚’é™¤å»ï¼‰
            # Wakeé€šçŸ¥å¾Œã®å¾…æ©Ÿï¼ˆå‘¼å¸/ä½“å‹¢ã‚’æ•´ãˆã‚‹ä½™è£•ã‚’ç¢ºä¿ï¼‰
            try:
                post_wait_ms = int(os.getenv("POST_WAKE_DELAY_MS", "600"))
            except Exception:
                post_wait_ms = 600
            time.sleep(max(0.0, post_wait_ms / 1000.0))
            audio_processor.clear_queue()
            
            # éŸ³å£°éŒ²éŸ³ãƒ•ã‚§ãƒ¼ã‚º
            rec_start = time.perf_counter()
            audio_data = speech_recorder.record_speech()
            rec_dur = time.perf_counter() - rec_start
            
            if len(audio_data) == 0:
                print("âš ï¸  éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                continue
            
            print(f"ğŸ“¦ éŒ²éŸ³å®Œäº† ({len(audio_data) / audio_config.SAMPLE_RATE:.1f}ç§’, â± {rec_dur:.2f}s)")
            logger.info(f"[{interaction_id}] éŒ²éŸ³å®Œäº† duration={rec_dur:.2f}s samples={len(audio_data)}")
            
            # ã‚µãƒ¼ãƒãƒ¼é€ä¿¡ã¾ãŸã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‡¦ç†
            online_start = time.perf_counter()
            success, response = send_to_server(audio_data, interaction_id)
            online_dur = time.perf_counter() - online_start
            
            if success and response:
                # ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å‡¦ç†æˆåŠŸ
                print("\n" + "-"*40)
                print(f"ğŸ†” ID: {response.get('interaction_id', interaction_id)}")
                transcript_raw = response.get("transcript", "")
                transcript = dedupe_transcript(transcript_raw)
                print("ğŸ“ èªè­˜çµæœ:", transcript)

                used_stream = False
                reply_text = response.get("reply", "")
                # Chat APIãŒä½¿ãˆã‚‹ãªã‚‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å„ªå…ˆ
                used_stream = False
                if server_config.PREFER_CHAT_API and server_config.CHAT_API_BASE_URL and server_config.CHAT_API_KEY:
                    try:
                        reply_text = llm_streaming_chat_api(transcript, interaction_id)
                        used_stream = True
                    except Exception as e:
                        logger.warning(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°APIåˆ©ç”¨ã«å¤±æ•—: {e}. ã‚µãƒ¼ãƒãƒ¼å¿œç­”/ãƒ­ãƒ¼ã‚«ãƒ«ã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°çµæœãŒç©ºã®å ´åˆã¯ã‚µãƒ¼ãƒãƒ¼å¿œç­”ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if used_stream and (not reply_text) and response.get("reply"):
                    reply_text = response.get("reply")
                    used_stream = False
                # æœ€çµ‚å‡ºåŠ›
                print("ğŸ¤– å¿œç­”:", reply_text)
                # ä»»æ„: ã‚µãƒ¼ãƒãƒ¼TTSã§å¿œç­”ã‚’èª­ã¿ä¸Šã’
                if server_config.ENABLE_TTS_PLAYBACK and reply_text:
                    speak_via_server_tts(reply_text, audio_processor)
                # ã‚µãƒ¼ãƒãƒ¼è¨ˆæ¸¬ãŒã‚ã‚Œã°è¡¨ç¤º
                timings = response.get("timings", {})
                if timings:
                    # Normalize to seconds whether server returns *_ms or seconds
                    if any(k.endswith('_ms') for k in timings.keys()):
                        asr = timings.get('asr_ms'); llm = timings.get('llm_ms'); total = timings.get('total_ms')
                        asr_s = (asr/1000.0) if isinstance(asr, (int, float)) else '-'
                        llm_s = (llm/1000.0) if isinstance(llm, (int, float)) else '-'
                        total_s = (total/1000.0) if isinstance(total, (int, float)) else '-'
                    else:
                        asr_s = timings.get('stt', '-')
                        llm_s = timings.get('llm', '-')
                        total_s = timings.get('total', '-')
                    if used_stream:
                        print(f"â± ã‚µãƒ¼ãƒãƒ¼å‡¦ç†: STT {asr_s}s, LLM(chat-api stream) -, TOTAL {total_s}s")
                    else:
                        print(f"â± ã‚µãƒ¼ãƒãƒ¼å‡¦ç†: STT {asr_s}s, LLM {llm_s}s, TOTAL {total_s}s")
                else:
                    print(f"â± ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¾€å¾©: {online_dur:.2f}s")
                print("-"*40 + "\n")
                logger.info(f"[{interaction_id}] ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æˆåŠŸ roundtrip={online_dur:.2f}s transcript_len={len(transcript)} reply_len={len(reply_text)} stream_used={used_stream}")
            else:
                # ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if server_config.LOCAL_STT_ENABLED:
                    print("ğŸ”„ ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§å‡¦ç†ä¸­...")
                    # ã‚ªãƒ•ãƒ©ã‚¤ãƒ³STT
                    t0 = time.perf_counter()
                    text = local_stt.transcribe(audio_data, audio_config.SAMPLE_RATE)
                    text = dedupe_transcript(text)
                    t1 = time.perf_counter()
                    
                    if text:
                        # å¿œç­”ç”Ÿæˆï¼ˆChat APIå„ªå…ˆã€‚ä¸å¯ãªã‚‰ãƒ­ãƒ¼ã‚«ãƒ«LLMï¼‰
                        used_stream = False
                        t2 = t1
                        reply = ""
                        if server_config.PREFER_CHAT_API and server_config.CHAT_API_BASE_URL and server_config.CHAT_API_KEY:
                            try:
                                t2a = time.perf_counter()
                                reply = llm_streaming_chat_api(text, interaction_id)
                                t2 = time.perf_counter()
                                used_stream = True
                            except Exception as e:
                                logger.warning(f"[offline] ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°APIå¤±æ•—: {e}. ãƒ­ãƒ¼ã‚«ãƒ«LLMã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
                        if not used_stream:
                            reply = llm_local_reply(text, interaction_id)
                            t2 = time.perf_counter()

                        print("\n" + "-"*40)
                        print(f"ğŸ†” ID: {interaction_id}")
                        print("ğŸ“ [ã‚ªãƒ•ãƒ©ã‚¤ãƒ³] èªè­˜çµæœ:", text)
                        print("ğŸ¤– [ã‚ªãƒ•ãƒ©ã‚¤ãƒ³] å¿œç­”:", reply)
                        if used_stream and not reply:
                            # ç©ºãªã‚‰ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                            reply = llm_local_reply(text, interaction_id)
                            t2 = time.perf_counter()
                            used_stream = False
                        if used_stream:
                            print(f"â± [ã‚ªãƒ•ãƒ©ã‚¤ãƒ³] STT {t1-t0:.2f}s, LLM(chat-api stream) ~{t2-t1:.2f}s, TOTAL {t2-t0:.2f}s")
                        else:
                            print(f"â± [ã‚ªãƒ•ãƒ©ã‚¤ãƒ³] STT {t1-t0:.2f}s, LLM {t2-t1:.2f}s, TOTAL {t2-t0:.2f}s")
                        print("-"*40 + "\n")
                        logger.info(f"[{interaction_id}] ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æˆåŠŸ stt={t1-t0:.2f}s llm={(t2-t1):.2f}s total={(t2-t0):.2f}s text_len={len(text)} reply_len={len(reply)} stream={used_stream}")
                    else:
                        print("âš ï¸  éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                        logger.warning(f"[{interaction_id}] ã‚ªãƒ•ãƒ©ã‚¤ãƒ³STTã§ãƒ†ã‚­ã‚¹ãƒˆãªã—")
                else:
                    print("âŒ ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    logger.error(f"[{interaction_id}] ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¤±æ•—ãƒ»ãƒ­ãƒ¼ã‚«ãƒ«ç„¡åŠ¹ã®ãŸã‚çµ‚äº†")
            
            print("ğŸ™  å†ã³Wake Wordå¾…æ©Ÿä¸­...")
            
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ çµ‚äº†ã—ã¾ã™...")
    except Exception as e:
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    finally:
        audio_processor.stop_stream()

if __name__ == "__main__":
    main()
