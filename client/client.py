#!/usr/bin/env python3
"""
Wake Saiteku Client - ç«¯æœ«å´ã®Wake Wordæ¤œçŸ¥ã¨éŸ³å£°é€ä¿¡ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å„ªå…ˆã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œ
"""

import os
import sys
import time
import json
import queue
import threading
import wave
import re
import requests
import tempfile
import logging
import logging.handlers
import uuid
from pathlib import Path
from typing import Optional, Tuple, List
from dataclasses import dataclass
from datetime import datetime

import numpy as np
import sounddevice as sd
import webrtcvad
import vosk

# ========== ãƒ­ã‚®ãƒ³ã‚°è¨­å®š ==========
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ­ã‚®ãƒ³ã‚°è¨­å®šï¼ˆæ—¥æ¬¡ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
def _configure_file_logging():
    level = os.getenv("LOG_LEVEL", "INFO").upper()
    logger.setLevel(getattr(logging, level, logging.INFO))
    if os.getenv("LOG_TO_FILE", "true").lower() == "true":
        default_dir = str((Path(__file__).resolve().parents[1] / "logs").resolve())
        log_dir = os.getenv("LOG_DIR", default_dir)
        try:
            os.makedirs(log_dir, exist_ok=True)
            handler = logging.handlers.TimedRotatingFileHandler(
                os.path.join(log_dir, "client.log"), when="midnight", backupCount=7, encoding="utf-8"
            )
            handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
            logger.addHandler(handler)
        except Exception as e:
            logger.warning(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®šã«å¤±æ•—: {e}")

_configure_file_logging()

# ========== è¨­å®š ==========
@dataclass
class AudioConfig:
    SAMPLE_RATE: int = 16000
    FRAME_DUR_MS: int = 20
    CHANNELS: int = 1
    DTYPE: str = 'int16'
    INPUT_DEVICE: Optional[str] = os.getenv("AUDIO_INPUT_DEVICE")  # device index or name
    
    @property
    def frame_length(self) -> int:
        return int(self.SAMPLE_RATE * self.FRAME_DUR_MS / 1000)

@dataclass
class WakeConfig:
    WAKE_TIMEOUT_S: float = float(os.getenv("WAKE_TIMEOUT_S", "2.5"))
    WAKE_REQUIRE_BOTH: bool = os.getenv("WAKE_REQUIRE_BOTH", "true").lower() == "true"
    WAKE_WORDS: List[Tuple[str, str]] = None
    
    def __post_init__(self):
        if self.WAKE_WORDS is None:
            self.WAKE_WORDS = [
                ("ã‚‚ã—ã‚‚ã—", r"ã‚‚ã—ã‚‚ã—"),
                ("ã‚µã‚¤ãƒ†ã‚¯", r"(ã‚µã‚¤ãƒ†ã‚¯|ã•ã„ã¦ã|ï½»ï½²ï¾ƒï½¸|ã•ã„ãƒ†ã‚¯|ã‚µã‚¤ãƒ†ãƒƒã‚¯|ã•ã„ã¦ã£ã|ã‚µã‚¤ãƒˆã‚¯|ã•ã„ã¨ã)")
            ]

@dataclass
class VADConfig:
    VAD_MODE: int = 2  # 0-3, 3ãŒæœ€ã‚‚å³ã—ã„
    MIN_UTTERANCE_MS: int = 400
    END_SILENCE_MS: int = 800
    MAX_RECORDING_MS: int = 10000

@dataclass
class ServerConfig:
    REMOTE_URL: str = os.getenv("SERVER_URL", "http://127.0.0.1:8000/inference")
    LOCAL_STT_ENABLED: bool = os.getenv("LOCAL_STT_ENABLED", "true").lower() == "true"
    LOCAL_LLM_URL: str = os.getenv("LLM_LOCAL_URL", "http://127.0.0.1:8081/v1/chat/completions")
    LOCAL_LLM_MODEL: str = os.getenv("LLM_LOCAL_MODEL", "local-model")
    REQUEST_TIMEOUT: int = int(os.getenv("REQUEST_TIMEOUT", "30"))

# è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
audio_config = AudioConfig()
wake_config = WakeConfig()
vad_config = VADConfig()
server_config = ServerConfig()

# ========== VoskåˆæœŸåŒ– ==========
def initialize_vosk(model_path: str = "wake-saiteku/models/ja") -> vosk.Model:
    """Voskãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–"""
    vosk.SetLogLevel(-1)  # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’æŠ‘åˆ¶
    
    if not os.path.isdir(model_path):
        logger.error(f"Voskæ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
        logger.info("ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        sys.exit(1)
    
    logger.info(f"Voskãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {model_path}")
    try:
        model = vosk.Model(model_path)
        logger.info("Voskãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿å®Œäº†")
        return model
    except Exception as e:
        logger.error(f"Voskãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
        sys.exit(1)

# ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
vosk_model = initialize_vosk()

# ========== ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå‡¦ç† ==========
class AudioProcessor:
    def __init__(self):
        self.q = queue.Queue()
        self.vad = webrtcvad.Vad(vad_config.VAD_MODE)
        self.stream = None
        self._last_level_log = 0.0
        self.last_frame_time = time.time()
        
    def audio_callback(self, indata, frames, time_info, status):
        """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        if status:
            logger.warning(f"ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status}")
        self.q.put(indata.copy())
        self.last_frame_time = time.time()
        
    def start_stream(self):
        """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹"""
        if self.stream is None:
            self.stream = sd.InputStream(
                channels=audio_config.CHANNELS,
                samplerate=audio_config.SAMPLE_RATE,
                dtype=audio_config.DTYPE,
                blocksize=audio_config.frame_length,
                device=audio_config.INPUT_DEVICE,
                callback=self.audio_callback
            )
            self.stream.start()
            # ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚’è¨˜éŒ²
            try:
                in_dev = None
                if audio_config.INPUT_DEVICE is not None:
                    in_dev = sd.query_devices(audio_config.INPUT_DEVICE)
                else:
                    default_in = sd.default.device[0]
                    in_dev = sd.query_devices(default_in)
                logger.info(f"ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹ device='{in_dev.get('name','unknown')}' samplerate={audio_config.SAMPLE_RATE}Hz block={audio_config.frame_length}")
            except Exception:
                logger.info("ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹")
    
    def stop_stream(self):
        """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢"""
        if self.stream:
            self.stream.stop()
            self.stream.close()
            self.stream = None
            logger.info("ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢")
    
    def get_audio_frame(self, timeout: Optional[float] = None) -> Optional[np.ndarray]:
        """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—"""
        try:
            return self.q.get(timeout=timeout)
        except queue.Empty:
            return None
    
    def clear_queue(self):
        """ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢"""
        while not self.q.empty():
            try:
                self.q.get_nowait()
            except queue.Empty:
                break

# ========== Wake Wordæ¤œçŸ¥ ==========
class WakeWordDetector:
    def __init__(self, model: vosk.Model):
        self.model = model
        self.recognizer = vosk.KaldiRecognizer(model, audio_config.SAMPLE_RATE)
        self._configure_grammar()
        self.text_history: List[Tuple[str, float]] = []
        
    def reset(self):
        """èªè­˜å™¨ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        self.recognizer = vosk.KaldiRecognizer(self.model, audio_config.SAMPLE_RATE)
        self._configure_grammar()
        self.text_history.clear()

    def _configure_grammar(self):
        """Wake Wordå°‚ç”¨ã®ç°¡æ˜“æ–‡æ³•ã‚’è¨­å®šï¼ˆèª¤æ¤œçŸ¥æŠ‘åˆ¶ï¼‰"""
        use_grammar = os.getenv("WAKE_USE_GRAMMAR", "true").lower() == "true"
        if not use_grammar:
            return
        phrases = [
            "ã‚‚ã—ã‚‚ã—",
            "ã‚‚ã—ã‚‚ã— ã‚µã‚¤ãƒ†ã‚¯",
            "ã‚‚ã—ã‚‚ã— ã‚µã‚¤ãƒ†ãƒƒã‚¯",
            "ã‚‚ã—ã‚‚ã— ã‚µã‚¤ãƒˆã‚¯",
            "ã‚µã‚¤ãƒ†ã‚¯",
            "ã‚µã‚¤ãƒ†ãƒƒã‚¯",
            "ã‚µã‚¤ãƒˆã‚¯",
            "ã•ã„ã¦ã",
            "ã•ã„ã¦ã£ã",
            "ã•ã„ã¨ã",
        ]
        try:
            self.recognizer.SetGrammar(json.dumps(phrases, ensure_ascii=False))
            logger.info("Wakeç”¨ç°¡æ˜“æ–‡æ³•ã‚’é©ç”¨ã—ã¾ã—ãŸ")
        except Exception as e:
            logger.warning(f"Wakeæ–‡æ³•è¨­å®šã«å¤±æ•—: {e}")
    
    def process_audio(self, pcm_data: bytes) -> bool:
        """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’å‡¦ç†ã—ã¦Wake Wordã‚’æ¤œå‡º"""
        current_time = time.time()
        
        # éŸ³å£°èªè­˜
        if self.recognizer.AcceptWaveform(pcm_data):
            result = json.loads(self.recognizer.Result())
            text = result.get("text", "")
            if text:
                self.text_history.append((text, current_time))
                logger.debug(f"èªè­˜: {text}")
        else:
            # éƒ¨åˆ†çµæœã‚‚å–å¾—
            partial_result = json.loads(self.recognizer.PartialResult())
            partial_text = partial_result.get("partial", "")
            if partial_text:
                self.text_history.append((partial_text, current_time))
                logger.debug(f"éƒ¨åˆ†èªè­˜: {partial_text}")
        
        # å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤
        cutoff_time = current_time - wake_config.WAKE_TIMEOUT_S - 0.5
        self.text_history = [(t, ts) for t, ts in self.text_history if ts >= cutoff_time]
        
        # Wake Wordæ¤œå‡º
        return self._check_wake_words()
    
    def _check_wake_words(self) -> bool:
        """Wake WordãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        current_time = time.time()
        recent_text = "".join([
            text for text, timestamp in self.text_history
            if current_time - timestamp <= wake_config.WAKE_TIMEOUT_S
        ])
        
        # Wake WordãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆé †åºã‚‚è€ƒæ…®ï¼‰
        if wake_config.WAKE_REQUIRE_BOTH:
            # ã€Œã‚‚ã—ã‚‚ã—ã€â†’ã€Œã‚µã‚¤ãƒ†ã‚¯ç³»ã€ã®é †ã‚’å„ªå…ˆ
            ok = bool(re.search(r"ã‚‚ã—ã‚‚ã—.*(ã‚µã‚¤ãƒ†ã‚¯|ã•ã„ã¦ã|ï½»ï½²ï¾ƒï½¸|ã•ã„ãƒ†ã‚¯|ã‚µã‚¤ãƒ†ãƒƒã‚¯|ã‚µã‚¤ãƒˆã‚¯|ã•ã„ã¨ã)", recent_text))
        else:
            ok = any(re.search(pattern, recent_text) for _, pattern in wake_config.WAKE_WORDS)
        if ok:
            logger.info(f"Wake Wordæ¤œå‡º: {recent_text}")
        return ok

# ========== éŸ³å£°éŒ²éŸ³ ==========
class SpeechRecorder:
    def __init__(self, audio_processor: AudioProcessor):
        self.audio_processor = audio_processor
        
    def record_speech(self) -> np.ndarray:
        """VADã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’éŒ²éŸ³"""
        logger.info("éŒ²éŸ³é–‹å§‹...")
        
        speech_frames = []
        voiced_ms = 0
        silence_ms = 0
        started = False
        
        start_time = time.time()
        
        while True:
            # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—
            pcm = self.audio_processor.get_audio_frame(timeout=1.0)
            if pcm is None:
                continue
            
            # VADåˆ¤å®š
            is_speech = self.audio_processor.vad.is_speech(
                pcm.tobytes(),
                audio_config.SAMPLE_RATE
            )
            
            speech_frames.append(pcm)
            
            if is_speech:
                voiced_ms += audio_config.FRAME_DUR_MS
                silence_ms = 0
                if not started and voiced_ms >= vad_config.MIN_UTTERANCE_MS:
                    started = True
                    logger.info("ç™ºè©±é–‹å§‹æ¤œå‡º")
            else:
                if started:
                    silence_ms += audio_config.FRAME_DUR_MS
            
            # çµ‚äº†æ¡ä»¶
            if started and silence_ms >= vad_config.END_SILENCE_MS:
                logger.info(f"ç™ºè©±çµ‚äº†æ¤œå‡º (ç„¡éŸ³ {silence_ms}ms)")
                break
            
            # æœ€å¤§éŒ²éŸ³æ™‚é–“
            if len(speech_frames) * audio_config.FRAME_DUR_MS > vad_config.MAX_RECORDING_MS:
                logger.warning("æœ€å¤§éŒ²éŸ³æ™‚é–“ã«åˆ°é”")
                break
            
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç™ºè©±ãŒå§‹ã¾ã‚‰ãªã„å ´åˆï¼‰
            if not started and (time.time() - start_time) > 5.0:
                logger.warning("ç™ºè©±ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                break
        
        if speech_frames:
            return np.concatenate(speech_frames, axis=0).reshape(-1)
        return np.array([], dtype=audio_config.DTYPE)

# ========== éŸ³å£°å‡¦ç† ==========
def save_wav(pcm_data: np.ndarray, filepath: str):
    """PCMãƒ‡ãƒ¼ã‚¿ã‚’WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
    with wave.open(filepath, 'wb') as wf:
        wf.setnchannels(audio_config.CHANNELS)
        wf.setsampwidth(2)  # int16
        wf.setframerate(audio_config.SAMPLE_RATE)
    wf.writeframes(pcm_data.tobytes())

def _dbfs(pcm: np.ndarray) -> float:
    """ç°¡æ˜“dBFSè¨ˆç®— (int16æƒ³å®š)"""
    if pcm.size == 0:
        return float("-inf")
    # 16-bit full scale
    rms = np.sqrt(np.mean((pcm.astype(np.float32) / 32768.0) ** 2))
    if rms <= 1e-8:
        return float("-inf")
    return 20.0 * np.log10(rms)

# ========== ã‚ªãƒ•ãƒ©ã‚¤ãƒ³STT ==========
def stt_offline_vosk(pcm_data: np.ndarray) -> str:
    """Voskã‚’ä½¿ç”¨ã—ãŸã‚ªãƒ•ãƒ©ã‚¤ãƒ³éŸ³å£°èªè­˜"""
    logger.info("ã‚ªãƒ•ãƒ©ã‚¤ãƒ³STTå‡¦ç†ä¸­...")
    
    recognizer = vosk.KaldiRecognizer(vosk_model, audio_config.SAMPLE_RATE)
    recognizer.SetWords(True)
    
    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
    recognizer.AcceptWaveform(pcm_data.tobytes())
    result = json.loads(recognizer.FinalResult())
    
    text = result.get("text", "").strip()
    logger.info(f"ã‚ªãƒ•ãƒ©ã‚¤ãƒ³STTçµæœ: {text}")
    return text

# ========== ã‚ªãƒ•ãƒ©ã‚¤ãƒ³LLM ==========
def llm_local_reply(prompt: str, interaction_id: str = "") -> str:
    """ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’ä½¿ç”¨ã—ãŸå¿œç­”ç”Ÿæˆ"""
    logger.info("ãƒ­ãƒ¼ã‚«ãƒ«LLMå‡¦ç†ä¸­...")
    
    payload = {
        "model": server_config.LOCAL_LLM_MODEL,
        "messages": [
            {
                "role": "system",
                "content": "ã‚ãªãŸã¯ã€Œã‚µã‚¤ãƒ†ã‚¯ã€ã¨ã„ã†åå‰ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æ—¥æœ¬èªã§ç°¡æ½”ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "temperature": 0.7,
        "max_tokens": 256
    }
    
    try:
        response = requests.post(
            server_config.LOCAL_LLM_URL,
            json=payload,
            headers={"X-Interaction-ID": interaction_id} if interaction_id else None,
            timeout=server_config.REQUEST_TIMEOUT
        )
        response.raise_for_status()
        
        result = response.json()
        reply = result["choices"][0]["message"]["content"]
        logger.info(f"ãƒ­ãƒ¼ã‚«ãƒ«LLMå¿œç­”: {reply[:50]}...")
        return reply
        
    except Exception as e:
        logger.error(f"ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚¨ãƒ©ãƒ¼: {e}")
        return f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€å¿œç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å…¥åŠ›: {prompt}"

# ========== ã‚µãƒ¼ãƒãƒ¼é€šä¿¡ ==========
def send_to_server(audio_data: np.ndarray, interaction_id: str) -> Tuple[bool, Optional[dict]]:
    """
    éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡
    
    Returns:
        (æˆåŠŸãƒ•ãƒ©ã‚°, ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿)
    """
    logger.info(f"ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡ä¸­: {server_config.REMOTE_URL}")
    
    # ä¸€æ™‚WAVãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
        tmp_path = tmp_file.name
    
    try:
        save_wav(audio_data, tmp_path)
        
        with open(tmp_path, "rb") as f:
            files = {"file": ("utterance.wav", f, "audio/wav")}
            response = requests.post(
                server_config.REMOTE_URL,
                files=files,
                headers={
                    "X-Interaction-ID": interaction_id,
                    "User-Agent": "WakeSaitekuClient/1.0"
                },
                timeout=server_config.REQUEST_TIMEOUT
            )
        
        response.raise_for_status()
        data = response.json()
        
        logger.info("ã‚µãƒ¼ãƒãƒ¼å¿œç­”å—ä¿¡æˆåŠŸ")
        return True, data
        
    except requests.exceptions.Timeout:
        logger.error("ã‚µãƒ¼ãƒãƒ¼ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
        return False, None
        
    except requests.exceptions.ConnectionError:
        logger.error("ã‚µãƒ¼ãƒãƒ¼æ¥ç¶šã‚¨ãƒ©ãƒ¼")
        return False, None
        
    except Exception as e:
        logger.error(f"ã‚µãƒ¼ãƒãƒ¼é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        return False, None
        
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        if os.path.exists(tmp_path):
            try:
                os.remove(tmp_path)
            except Exception as e:
                logger.warning(f"ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")

# ========== ãƒ¡ã‚¤ãƒ³å‡¦ç† ==========
def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
    print("\n" + "="*50)
    print("Wake Saiteku ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ")
    print("="*50)
    print(f"ğŸ™  Wake Wordå¾…æ©Ÿä¸­: ã€Œã‚‚ã—ã‚‚ã—ã‚µã‚¤ãƒ†ã‚¯ã€")
    print(f"ğŸ“¡ ã‚µãƒ¼ãƒãƒ¼: {server_config.REMOTE_URL}")
    print(f"ğŸ”§ ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if server_config.LOCAL_STT_ENABLED else 'ç„¡åŠ¹'}")
    logger.info(f"è¨­å®š: REMOTE_URL={server_config.REMOTE_URL}, LOCAL_STT_ENABLED={server_config.LOCAL_STT_ENABLED}, LOCAL_LLM_URL={server_config.LOCAL_LLM_URL}, REQUEST_TIMEOUT={server_config.REQUEST_TIMEOUT}s")
    print("="*50 + "\n")
    
    # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–
    audio_processor = AudioProcessor()
    wake_detector = WakeWordDetector(vosk_model)
    speech_recorder = SpeechRecorder(audio_processor)
    
    # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
    audio_processor.start_stream()
    
    try:
        while True:
            # Wake Wordæ¤œå‡ºãƒ•ã‚§ãƒ¼ã‚º
            logger.info("Wake Wordå¾…æ©Ÿä¸­...")
            wake_detector.reset()
            audio_processor.clear_queue()
            
            min_db = float(os.getenv("WAKE_MIN_DBFS", "-55"))
            while True:
                pcm = audio_processor.get_audio_frame(timeout=1.0)
                if pcm is None:
                    # ã—ã°ã‚‰ããƒ•ãƒ¬ãƒ¼ãƒ ãŒæ¥ãªã„å ´åˆã¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å¾©å¸°
                    if time.time() - audio_processor.last_frame_time > 3.0:
                        logger.warning("ğŸ¤ éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ãŒ3ç§’ä»¥ä¸Šå±Šã„ã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å†èµ·å‹•ã—ã¾ã™ã€‚")
                        try:
                            audio_processor.stop_stream()
                            time.sleep(0.2)
                            audio_processor.start_stream()
                        except Exception as e:
                            logger.error(f"ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ å†èµ·å‹•ã«å¤±æ•—: {e}")
                            time.sleep(0.5)
                    continue
                
                # 1ç§’æ¯ã«å…¥åŠ›ãƒ¬ãƒ™ãƒ«ã‚’INFOã§å‡ºã™ï¼ˆå‹•ä½œç¢ºèªç”¨ï¼‰
                now = time.time()
                if now - audio_processor._last_level_log >= 1.0:
                    level = _dbfs(pcm.reshape(-1))
                    logger.info(f"ğŸšï¸ å…¥åŠ›ãƒ¬ãƒ™ãƒ«: {level:.1f} dBFS")
                    audio_processor._last_level_log = now

                # ãƒ¬ãƒ™ãƒ«ãŒä½ã™ãã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆèª¤æ¤œçŸ¥æŠ‘åˆ¶ï¼‰
                if _dbfs(pcm.reshape(-1)) < min_db:
                    continue

                if wake_detector.process_audio(pcm.tobytes()):
                    # ç™ºè©±å‡¦ç†ã”ã¨ã®ç›¸é–¢IDã‚’æ¡ç•ª
                    interaction_id = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ") + "-" + uuid.uuid4().hex[:8]
                    print("\nâœ… Wake Wordæ¤œå‡º!")
                    print(f"ğŸ†” ID: {interaction_id}")
                    logger.info(f"[{interaction_id}] Wake Wordæ¤œå‡º")
                    print("ğŸ“¢ ãŠè©±ã—ãã ã•ã„...")
                    break
            
            # å°‘ã—å¾…ã£ã¦ã‚­ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªã‚¢ï¼ˆWake Wordã®æ®‹éŸ¿ã‚’é™¤å»ï¼‰
            time.sleep(0.2)
            audio_processor.clear_queue()
            
            # éŸ³å£°éŒ²éŸ³ãƒ•ã‚§ãƒ¼ã‚º
            rec_start = time.perf_counter()
            audio_data = speech_recorder.record_speech()
            rec_dur = time.perf_counter() - rec_start
            
            if len(audio_data) == 0:
                print("âš ï¸  éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                continue
            
            print(f"ğŸ“¦ éŒ²éŸ³å®Œäº† ({len(audio_data) / audio_config.SAMPLE_RATE:.1f}ç§’, â± {rec_dur:.2f}s)")
            logger.info(f"[{interaction_id}] éŒ²éŸ³å®Œäº† duration={rec_dur:.2f}s samples={len(audio_data)}")
            
            # ã‚µãƒ¼ãƒãƒ¼é€ä¿¡ã¾ãŸã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‡¦ç†
            online_start = time.perf_counter()
            success, response = send_to_server(audio_data, interaction_id)
            online_dur = time.perf_counter() - online_start
            
            if success and response:
                # ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å‡¦ç†æˆåŠŸ
                print("\n" + "-"*40)
                print(f"ğŸ†” ID: {response.get('interaction_id', interaction_id)}")
                print("ğŸ“ èªè­˜çµæœ:", response.get("transcript", ""))
                print("ğŸ¤– å¿œç­”:", response.get("reply", ""))
                # ã‚µãƒ¼ãƒãƒ¼è¨ˆæ¸¬ãŒã‚ã‚Œã°è¡¨ç¤º
                timings = response.get("timings", {})
                if timings:
                    print(f"â± ã‚µãƒ¼ãƒãƒ¼å‡¦ç†: STT {timings.get('stt','-')}s, LLM {timings.get('llm','-')}s, TOTAL {timings.get('total','-')}s")
                else:
                    print(f"â± ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¾€å¾©: {online_dur:.2f}s")
                print("-"*40 + "\n")
                logger.info(f"[{interaction_id}] ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æˆåŠŸ roundtrip={online_dur:.2f}s transcript_len={len(response.get('transcript',''))} reply_len={len(response.get('reply',''))}")
            else:
                # ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if server_config.LOCAL_STT_ENABLED:
                    print("ğŸ”„ ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§å‡¦ç†ä¸­...")
                    # ã‚ªãƒ•ãƒ©ã‚¤ãƒ³STT
                    t0 = time.perf_counter()
                    text = stt_offline_vosk(audio_data)
                    t1 = time.perf_counter()
                    
                    if text:
                        # ã‚ªãƒ•ãƒ©ã‚¤ãƒ³LLM
                        reply = llm_local_reply(text, interaction_id)
                        t2 = time.perf_counter()
                        
                        print("\n" + "-"*40)
                        print(f"ğŸ†” ID: {interaction_id}")
                        print("ğŸ“ [ã‚ªãƒ•ãƒ©ã‚¤ãƒ³] èªè­˜çµæœ:", text)
                        print("ğŸ¤– [ã‚ªãƒ•ãƒ©ã‚¤ãƒ³] å¿œç­”:", reply)
                        print(f"â± [ã‚ªãƒ•ãƒ©ã‚¤ãƒ³] STT {t1-t0:.2f}s, LLM {t2-t1:.2f}s, TOTAL {t2-t0:.2f}s")
                        print("-"*40 + "\n")
                        logger.info(f"[{interaction_id}] ã‚ªãƒ•ãƒ©ã‚¤ãƒ³æˆåŠŸ stt={t1-t0:.2f}s llm={t2-t1:.2f}s total={t2-t0:.2f}s text_len={len(text)} reply_len={len(reply)}")
                    else:
                        print("âš ï¸  éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                        logger.warning(f"[{interaction_id}] ã‚ªãƒ•ãƒ©ã‚¤ãƒ³STTã§ãƒ†ã‚­ã‚¹ãƒˆãªã—")
                else:
                    print("âŒ ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    logger.error(f"[{interaction_id}] ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¤±æ•—ãƒ»ãƒ­ãƒ¼ã‚«ãƒ«ç„¡åŠ¹ã®ãŸã‚çµ‚äº†")
            
            print("ğŸ™  å†ã³Wake Wordå¾…æ©Ÿä¸­...")
            
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ çµ‚äº†ã—ã¾ã™...")
    except Exception as e:
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
    finally:
        audio_processor.stop_stream()

if __name__ == "__main__":
    main()
